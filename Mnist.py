import streamlit as st
import mlflow
import mlflow.sklearn
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import fetch_openml
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.svm import SVC
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import accuracy_score
from sklearn.cluster import KMeans, DBSCAN
from sklearn.decomposition import PCA
from sklearn.manifold import TSNE
from sklearn.neural_network import MLPClassifier

# T·∫£i d·ªØ li·ªáu MNIST (Cache ƒë·ªÉ tƒÉng t·ªëc)
@st.cache_data
def load_data():
    mnist = fetch_openml('mnist_784', version=1)
    return mnist.data, mnist.target.astype(int)

X, y = load_data()

# Sidebar - Menu ƒëi·ªÅu h∆∞·ªõng
st.sidebar.title("üìå Menu ·ª®ng D·ª•ng")
app_mode = st.sidebar.radio("Ch·ªçn ch·ª©c nƒÉng", [
    "Classification MNIST", "Clustering Algorithms",
    "Neural Network", "PCA t-SNE", "Semi-Supervised"
])

def log_mlflow(model, X_valid, y_valid, model_name):
    with mlflow.start_run():
        mlflow.log_param("Model", model_name)
        mlflow.sklearn.log_model(model, model_name)
        y_pred = model.predict(X_valid)
        acc = accuracy_score(y_valid, y_pred)
        mlflow.log_metric("Accuracy", acc)

# --- CH·ª®C NƒÇNG PH√ÇN LO·∫†I ---
if app_mode == "Classification MNIST":
    st.title("üîç Ph√¢n lo·∫°i ch·ªØ s·ªë MNIST")
    
    if "page" not in st.session_state:
        st.session_state.page = "theory"
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üìñ L√Ω thuy·∫øt"):
            st.session_state.page = "theory"
    with col2:
        if st.button("‚öôÔ∏è Hu·∫•n luy·ªán m√¥ h√¨nh"):
            st.session_state.page = "training"
    
    if st.session_state.page == "theory":
        st.header("üìñ L√Ω thuy·∫øt v·ªÅ ph√¢n lo·∫°i ch·ªØ s·ªë MNIST")
        st.markdown("""
        B·ªô d·ªØ li·ªáu MNIST ch·ª©a 70.000 h√¨nh ·∫£nh ch·ªØ s·ªë vi·∫øt tay (0-9), m·ªói ·∫£nh c√≥ k√≠ch th∆∞·ªõc 28x28 pixel.
        ƒê√¢y l√† m·ªôt trong nh·ªØng b·ªô d·ªØ li·ªáu ph·ªï bi·∫øn nh·∫•t trong lƒ©nh v·ª±c Machine Learning v√† Deep Learning.
        
        **1. ƒê·ªãnh d·∫°ng d·ªØ li·ªáu**
        - M·ªói ·∫£nh l√† m·ªôt ma tr·∫≠n 28x28 pixel, ƒë∆∞·ª£c chuy·ªÉn th√†nh vector c√≥ 784 chi·ªÅu.
        - Gi√° tr·ªã pixel n·∫±m trong kho·∫£ng t·ª´ 0 ƒë·∫øn 255 (c√≥ th·ªÉ ƒë∆∞·ª£c chu·∫©n h√≥a v·ªÅ kho·∫£ng [0,1]).
        
        **2. C√°c thu·∫≠t to√°n ƒë∆∞·ª£c s·ª≠ d·ª•ng:**
        - **Decision Tree**: D·ªÖ hi·ªÉu, d·ªÖ tri·ªÉn khai, nh∆∞ng c√≥ th·ªÉ b·ªã overfitting.
        - **SVM (Support Vector Machine)**: Hi·ªáu su·∫•t cao nh∆∞ng c√≥ th·ªÉ ch·∫≠m tr√™n t·∫≠p d·ªØ li·ªáu l·ªõn.
        
        **3. ·ª®ng d·ª•ng th·ª±c t·∫ø**
        - Nh·∫≠n d·∫°ng ch·ªØ vi·∫øt tay trong h·ªá th·ªëng nh·∫≠p li·ªáu t·ª± ƒë·ªông.
        - Chuy·ªÉn ƒë·ªïi t√†i li·ªáu vi·∫øt tay sang vƒÉn b·∫£n s·ªë h√≥a.
        - H·ªó tr·ª£ h·ªá th·ªëng nh·∫≠n di·ªán ch·ªØ s·ªë tr√™n s√©c ng√¢n h√†ng, bi·ªÉn s·ªë xe.
        """)
    
    
    elif st.session_state.page == "training":
        st.header("‚öôÔ∏è Hu·∫•n luy·ªán m√¥ h√¨nh")
        
        # Chia d·ªØ li·ªáu
        train_size = st.slider("Train (%)", 50, 80, 70)
        val_size = st.slider("Validation (%)", 10, 30, 15)
        sample_size = st.slider("S·ªë m·∫´u train", 1000, 10000, 5000)
        
        X_train, X_temp, y_train, y_temp = train_test_split(X, y, train_size=train_size/100, stratify=y)
        X_valid, X_test, y_valid, y_test = train_test_split(X_temp, y_temp, test_size=val_size/(100-train_size), stratify=y_temp)
        
        # Ch·ªçn m√¥ h√¨nh
        model_choice = st.selectbox("Ch·ªçn m√¥ h√¨nh", ["Decision Tree", "SVM"])
        
        if st.button("üöÄ Hu·∫•n luy·ªán"):
            if model_choice == "Decision Tree":
                model = DecisionTreeClassifier()
            else:
                model = SVC()
            
            model.fit(X_train[:sample_size], y_train[:sample_size])
            acc = accuracy_score(y_valid, model.predict(X_valid))
            st.write(f"üéØ ƒê·ªô ch√≠nh x√°c tr√™n t·∫≠p validation: {acc:.4f}")
            
            # Log MLFlow
            log_mlflow(model, X_valid, y_valid, model_choice)
            
            # Demo d·ª± ƒëo√°n
            st.subheader("üé® Demo d·ª± ƒëo√°n")
            indices = np.random.choice(len(X_test), 5, replace=False)
            X_test = np.array(X_test)  # Chuy·ªÉn th√†nh numpy array ƒë·ªÉ tr√°nh l·ªói KeyError
            fig, axes = plt.subplots(1, 5, figsize=(10, 2))
            for i, idx in enumerate(indices):
                axes[i].imshow(X_test[idx].reshape(28, 28), cmap="gray")
                axes[i].axis("off")
                pred = model.predict([X_test[idx]])[0]
                axes[i].set_title(f"D·ª± ƒëo√°n: {pred}")
            st.pyplot(fig)


# --- CH·ª®C NƒÇNG PH√ÇN C·ª§M ---
if app_mode == "Clustering Algorithms":
    st.title("üîç Ph√¢n c·ª•m ch·ªØ s·ªë MNIST")
    
    if "page" not in st.session_state:
        st.session_state.page = "theory"
    
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üìñ L√Ω thuy·∫øt"):
            st.session_state.page = "theory"
    with col2:
        if st.button("‚öôÔ∏è Hu·∫•n luy·ªán m√¥ h√¨nh"):
            st.session_state.page = "training"
    
    if st.session_state.page == "theory":
        st.header("üìñ L√Ω thuy·∫øt v·ªÅ ph√¢n c·ª•m")
        st.markdown("""
        Ph√¢n c·ª•m l√† m·ªôt k·ªπ thu·∫≠t trong Machine Learning nh·∫±m nh√≥m c√°c ƒëi·ªÉm d·ªØ li·ªáu t∆∞∆°ng ƒë·ªìng l·∫°i v·ªõi nhau. Trong b√†i to√°n MNIST, ph√¢n c·ª•m gi√∫p ch√∫ng ta ph√°t hi·ªán c√°c nh√≥m ch·ªØ s·ªë t∆∞∆°ng t·ª± m√† kh√¥ng c·∫ßn nh√£n tr∆∞·ªõc.
    
    **1. K-means**
    - L√† thu·∫≠t to√°n ph√¢n c·ª•m ph·ªï bi·∫øn nh·∫•t.
    - Ho·∫°t ƒë·ªông b·∫±ng c√°ch g√°n d·ªØ li·ªáu v√†o K c·ª•m d·ª±a tr√™n kho·∫£ng c√°ch t·ªõi t√¢m c·ª•m.
    - C·∫≠p nh·∫≠t l·∫°i t√¢m c·ª•m d·ª±a tr√™n trung b√¨nh c·ªßa c√°c ƒëi·ªÉm trong c·ª•m cho ƒë·∫øn khi h·ªôi t·ª•.
    - Nh∆∞·ª£c ƒëi·ªÉm: C·∫ßn x√°c ƒë·ªãnh tr∆∞·ªõc s·ªë c·ª•m K, c√≥ th·ªÉ b·ªã ·∫£nh h∆∞·ªüng b·ªüi gi√° tr·ªã ban ƒë·∫ßu.
    
    **2. DBSCAN**
    - DBSCAN (Density-Based Spatial Clustering of Applications with Noise) l√† thu·∫≠t to√°n ph√¢n c·ª•m d·ª±a tr√™n m·∫≠t ƒë·ªô.
    - Ho·∫°t ƒë·ªông b·∫±ng c√°ch t√¨m ki·∫øm c√°c v√πng d·ªØ li·ªáu c√≥ m·∫≠t ƒë·ªô cao v√† m·ªü r·ªông c·ª•m t·ª´ c√°c ƒëi·ªÉm l√µi.
    - C√≥ kh·∫£ nƒÉng ph√°t hi·ªán nhi·ªÖu t·ªët h∆°n K-means.
    - Nh∆∞·ª£c ƒëi·ªÉm: C·∫ßn x√°c ƒë·ªãnh tr∆∞·ªõc hai tham s·ªë: Epsilon (kho·∫£ng c√°ch t·ªëi ƒëa ƒë·ªÉ x√°c ƒë·ªãnh h√†ng x√≥m) v√† min_samples (s·ªë ƒëi·ªÉm t·ªëi thi·ªÉu ƒë·ªÉ t·∫°o th√†nh c·ª•m).
    
    **·ª®ng d·ª•ng th·ª±c t·∫ø:**
    - Nh·∫≠n di·ªán ch·ªØ vi·∫øt tay khi kh√¥ng c√≥ nh√£n s·∫µn.
    - Ph√°t hi·ªán b·∫•t th∆∞·ªùng trong d·ªØ li·ªáu s·ªë.
    - T·∫°o nh√≥m ng∆∞·ªùi d√πng c√≥ h√†nh vi t∆∞∆°ng ƒë·ªìng tr√™n h·ªá th·ªëng.""")
    
    elif st.session_state.page == "training":
        st.header("‚öôÔ∏è Hu·∫•n luy·ªán m√¥ h√¨nh")
        clustering_method = st.selectbox("Ch·ªçn thu·∫≠t to√°n ph√¢n c·ª•m", ["K-means", "DBSCAN"])
        num_samples = st.slider("S·ªë l∆∞·ª£ng m·∫´u s·ª≠ d·ª•ng", 1000, 10000, 5000, step=1000)
        sample_indices = np.random.choice(len(X), num_samples, replace=False)
        X_sample = X.iloc[sample_indices]
        
        @st.cache_data
        def reduce_dimensionality(X_data, n_components=2):
            pca = PCA(n_components=n_components)
            return pca.fit_transform(X_data)
        
        X_pca = reduce_dimensionality(X_sample)
        
        if clustering_method == "K-means":
            k = st.slider("S·ªë c·ª•m (K)", 2, 20, 10)
            model = KMeans(n_clusters=k, random_state=42)
        else:
            eps = st.slider("Epsilon (DBSCAN)", 0.1, 5.0, 1.0)
            min_samples = st.slider("S·ªë m·∫´u t·ªëi thi·ªÉu", 2, 20, 5)
            model = DBSCAN(eps=eps, min_samples=min_samples)
        
        if st.button("üöÄ Th·ª±c hi·ªán ph√¢n c·ª•m"):
            labels = model.fit_predict(X_sample)
            log_mlflow(model, X_sample, labels, clustering_method)
            
            st.success("‚úÖ Ph√¢n c·ª•m ho√†n th√†nh!")
            fig, ax = plt.subplots()
            scatter = ax.scatter(X_pca[:, 0], X_pca[:, 1], c=labels, cmap='viridis', alpha=0.5)
            legend1 = ax.legend(*scatter.legend_elements(), title="C·ª•m")
            ax.add_artist(legend1)
            st.pyplot(fig)
# --- CH·ª®C NƒÇNG PCA & t-SNE ---
if app_mode == "PCA t-SNE":
    st.title("üìâ PCA & t-SNE tr√™n MNIST")
    
    method = st.radio("Ch·ªçn ph∆∞∆°ng ph√°p gi·∫£m chi·ªÅu:", ["PCA", "t-SNE"])
    num_components = st.slider("S·ªë chi·ªÅu gi·∫£m xu·ªëng", 2, 50, 2)
    
    if st.button("üîÑ Th·ª±c hi·ªán gi·∫£m chi·ªÅu"):
        if method == "PCA":
            reducer = PCA(n_components=num_components)
        else:
            reducer = TSNE(n_components=2, perplexity=30, random_state=42)
        
        X_reduced = reducer.fit_transform(X[:5000])
        
        # Log MLFlow
        with mlflow.start_run():
            mlflow.log_param("Method", method)
            mlflow.log_param("Components", num_components)
        
        # Hi·ªÉn th·ªã k·∫øt qu·∫£
        st.subheader("üìä K·∫øt qu·∫£ tr·ª±c quan h√≥a")
        fig, ax = plt.subplots()
        scatter = ax.scatter(X_reduced[:, 0], X_reduced[:, 1], c=y[:5000], cmap="jet", alpha=0.5)
        fig.colorbar(scatter)
        st.pyplot(fig)
# --- NEURAL NETWORK ---
if app_mode == "Neural Network":
    st.title("üß† Neural Network tr√™n MNIST")
    
    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y)
    scaler = StandardScaler()
    X_train = scaler.fit_transform(X_train)
    X_test = scaler.transform(X_test)
    
    hidden_layers = st.slider("S·ªë neuron m·ªói l·ªõp ·∫©n", 10, 200, 50)
    num_layers = st.slider("S·ªë l·ªõp ·∫©n", 1, 5, 2)
    activation = st.selectbox("Activation Function", ["relu", "tanh", "logistic"])
    optimizer = st.selectbox("Optimizer", ["adam", "sgd", "lbfgs"])
    epochs = st.slider("S·ªë epoch", 10, 100, 50)
    
    if st.button("üöÄ Hu·∫•n luy·ªán m√¥ h√¨nh"):
        model = MLPClassifier(hidden_layer_sizes=(hidden_layers,) * num_layers, 
                              activation=activation, solver=optimizer,
                              max_iter=epochs, random_state=42)
        model.fit(X_train, y_train)
        acc = accuracy_score(y_test, model.predict(X_test))
        
        st.write(f"üéØ ƒê·ªô ch√≠nh x√°c: {acc:.4f}")
        log_mlflow(model, X_test, y_test, "Neural Network")
        
        # Bi·ªÉu ƒë·ªì Loss Curve
        st.subheader("üìâ Bi·ªÉu ƒë·ªì Loss Curve")
        fig, ax = plt.subplots()
        ax.plot(model.loss_curve_)
        ax.set_xlabel("Epoch")
        ax.set_ylabel("Loss")
        ax.set_title("Qu√° tr√¨nh hu·∫•n luy·ªán")
        st.pyplot(fig)
        
        # Demo d·ª± ƒëo√°n
        st.subheader("üé® Demo d·ª± ƒëo√°n")
        indices = np.random.choice(len(X_test), 5, replace=False)
        fig, axes = plt.subplots(1, 5, figsize=(10, 2))
        for i, idx in enumerate(indices):
            axes[i].imshow(X_test[idx].reshape(28, 28), cmap="gray")
            axes[i].axis("off")
            pred = model.predict([X_test[idx]])[0]
            axes[i].set_title(f"D·ª± ƒëo√°n: {pred}")
        st.pyplot(fig)

